\section{Likelihood formalism}
\label{sec:likelihoods}

The observables measured in events containing tau lepton pairs 
do not provide sufficient information to fully determine the tau--pair mass, $M_{\tau\tau}$.
Depending on whether the two tau leptons decay hadronically or leptonically, 
the kinematics of the tau--pair decays depends upon $4$--$6$ parameters,
the angles $4$ $\theta_{1}$, $\overline{\phi_{1}}$ and $\theta_{2}$, $\overline{\phi_{2}}$
plus $0$--$2$ masses $\mnus^{1}$ and $\mnus^{2}$,
as described in section~\ref{sec:tau_decay_kinematics}.
This contrasts with only $2$ observables which constrain the momenta of the neutrinos produced in the tau decays:
the two components \METx and \METy of the reconstructed missing transverse momentum, \MET.
%The two \MET components are reconstructed with non--negligible experimental reconstruction,
%amounting to typically $\sigma$\METx$ = \sigma$\METy$ \sim 15$~GeV in the 2011/2012 data--taking period~\cite{DP_12_003,DP_12_013}.

In the SVfit algorithm the fact that the tau decay kinematics is underconstrained by measured observables is handled via a likelihood approach.
The likelihood approach utilized by SVfit allows for a reconstruction of the tau--pair mass on an event--by--event basis.
The term {\em Dynamical Likelihood Methods} (DLM) has been introduced for the application of likelihood methods 
for the purpose of reconstructing kinematic quantities on an event--by--event basis~\cite{Kondo:1988,Kondo:1991}.
$M_{\tau\tau}$ values are reconstructed by combining the measured observables \METx and \METy with a probability model.
The present version of SVfit includes terms for tau decay kinematics and for the \MET resolution~\footnote{
  We foresee to include tau decay vertex information in future versions of the SVfit algorithm.
  The idea of using decay vertex information in the $M_{\tau\tau}$ reconstruction is actually what SVfit owes its name to.
}.
The model makes a prediction for the probability density $p(\vec{x} \vert \vec{y}, \vec{a})$ 
to observe the values $\vec{x} = (\METx, \METy)$ measured in an event,
given that the unknown parameters specifying the kinematics of the tau--pair decay have values
$\vec{a} = (\theta_{1}, \overline{\phi_{1}}, \theta_{2}, \overline{\phi_{2}}, \mnus^{1}, \mnus^{2})$
and the four--momenta of the visible decay products are $\vec{y} = (p^{vis}_{1}, p^{vis}_{2}$.

Two different methods exist for determining the best estimate for $\vec{a}$, 
given the measured values $\vec{x}$ and $\vec{y}$ and a probability density $p(\vec{x} \vert \vec{y}, \vec{a})$.

In the first method, called {\em marginalization}, a probability 
\begin{equation}
P(M_{\tau\tau}) = \int \delta \left( M_{\tau\tau} - M_{\tau\tau}(\vec{y}, \vec{a} \right) p(\vec{x} \vert \vec{y}, \vec{a}) d\vec{a}
\end{equation}
is computed.
The integration of the probability densities is performed using the VEGAS~\cite{VEGAS} algorithm by SVfit.
In order to find the best estimate for $M_{\tau\tau}$,
a series of $P(M_{\tau\tau})$ values is
computed for an ascending series of mass hypotheses $M_{\tau\tau}$~\footnote{
  The probabilities $P(M_{\tau\tau})$ are computed in steps in the mass hypothesis.  
  The steps are defined by the recursive relation $\delta M _{i+1} = 1.025 \times \delta M_{i}$, 
  where $\delta M_{0} = 2.5~\GeV$, within the range $M_{\tau\tau} \in [5, 2000]$~\GeV.
}.
The best estimate $\hat{M}_{\tau\tau}$ for the tau--pair mass is taken to be the maximum $M_{\tau\tau}$ value within the series.
Lower (upper) limits on the reconstructed mass $\hat{M}_{\tau\tau}$ are determined for every event
by the $0.16$ ($0.84$) quantiles of the series of mass hypotheses $M_{\tau\tau}^{i}$
and associated probability values $P(M_{\tau\tau}^{i})$.

Alternative to finding $M_{\tau\tau}$ solutions by marginalization of the probability densities,
estimates for $M_{\tau\tau}$ may be obtained via the {\em profile likelihood method}.
In the latter,
the best estimate for the tau--pair mass is obtained by maximizing the probability density
$p(\vec{x} \vert \vec{y}, \vec{a})$ with respect to all parameters $\vec{a}$ which do not correspond to measured observables:
\begin{equation*}
p(\vec{x} \vert \vec{y}, \hat{a}) = \max_{\vec{a}} p(\vec{x} \vert \vec{y}, \vec{a}).
\end{equation*}
The best estimate $\hat{M}_{\tau\tau}$ for the tau--pair mass is then taken to be $\hat{M}_{\tau\tau} = M_{\tau\tau}(\vec{y}, \hat{a})$.
Uncertainties on the reconstructed mass $\hat{M}_{\tau\tau}$ are computed by varying the parameters $\hat{a}$ 
within the region by which the negative logarithm of the probability density $p(\vec{x} \vert \vec{y}, \vec{a})$ 
increases by $0.5$ units with respect to the best fit value $p(\vec{x} \vert \vec{y}, \hat{a})$.

Conceptual complications in using the profile likelihood method in the context of DLM
arise from the fact that probability densities, not probabilities, need to be maximized.
The issue with probability densities is that Jacobian terms $\partial y/\partial y'$ come into existence
in case variables are reparametrized according to $\vec{y} \mapsto \vec{y}' = f(\vec{y})$.
The Jacobian terms are expected to have little effect on the final result in case the likelihood functions are well constrained by the measured observables.
This assumption is not always true when applying likelihood methods to single events.
Besides, the Jacobian terms introduce an undesirable element of arbitrariness.
A second issue of reconstructing kinematic quantities via maximization of likelihood functions
is that estimates of kinematic quantities may be biased.
In case the width of likelihood functions varies as function of the value of the kinematic quantity of interest,
the profile likelihood method gives preference to solutions for which the likelihood functions are narrow and peaked.
In SVfit, we reduce potential biases of this kind by making the widths of likelihood functions
independent of $M_{\tau\tau}$ via suitable reparametrization of the variables $\vec{y}$.
We add a pseudo--Jacobian term of the form $\sin \theta_{1} \cdot \sin \theta_{2} \cdot \log M_{\tau\tau}$ to the likelihood function
in case $M_{\tau\tau}$ solutions are computed by the profile likelihood method.
The pseudo--Jacobian term is purely artificial. The motivation to add this term is that we find it to improve the resolution.
The maximization of the likelihood functions is performed using the MINUIT~\cite{MINUIT} package.
The main advantage of reconstructing $M_{\tau\tau}$ via the profile likelihood method
is that MINUIT fits may be substantially less computationally extensive than the numerical integrations performed by VEGAS~\footnote{  
  Computing the $M_{\tau\tau}$ solution for a single event typically takes $1$~s ($10$~ms) 
  in case the solution is obtained via the marginalization (profile likelihood method) on a $2.27$~GHz Intel\TReg~Xeon\TReg~L5520 processor.
}.

The likelihood functions $\cal{L}$ entering the probability density $p(\vec{x} \vert \vec{y}, \vec{a}) = \prod \cal{L}$ 
are described in the following sections.
We consider two different probability models for the tau lepton decay kinematics,
detailed in sections~\ref{sec:psKine} and~\ref{sec:meKine} respectively.
The likelihood term based on \MET is described in section~\ref{sec:likelihoods_met}.


\subsection{Tau decays}
\label{sec:likelihoods_taudecay}

define visible energy fraction $X$ = visEn/tauLeptonEn

\begin{figure}
\setlength{\unitlength}{1mm}
\begin{center}
\begin{picture}(150,60)(0,0)
\put(-0.5, 2){\mbox{\includegraphics*[height=58mm]
  {figures/makeSVfitToyMCplots_X1_m90_beforeVisPtCuts.pdf}}}
\put(78.0, 2){\mbox{\includegraphics*[height=58mm]
  {figures/makeSVfitToyMCplots_X2_m90_beforeVisPtCuts.pdf}}}
\end{picture}
\caption{\captiontext 
  Distributions of the visible energy fraction $X$ in simulated 
  $\tau \rightarrow \ell\nu\nu$ (left) and $\tau \rightarrow \tau_{had}\nu$ (right) decays (simulated by~\cite{tauola})
  compared to ``Phase--Space'' and ``Matrix Element'' models.
}
\label{fig:visEnFractionModelComparisson}
\end{center}
\end{figure} 

\subsubsection{Phase--space model}
\label{sec:psKine} 

\subsubsection{Matrix element model}
\label{sec:meKine}

\subsection{Missing $E_{T}$}
\label{sec:likelihoods_met}

The \MET likelihood quantifies the compatibility of a tau decay hypothesis
with the missing transverse momentum reconstructed in an event.
Assuming that the neutrinos produced in tau decays are the only source of \MET,
momentum conservation in the plane perpendicular to the beam axis implies that
the vectorial sum of neutrino momenta matches the reconstructed \MET~\footnote{
  Energy and momentum conservation in longitudinal direction cannot be used to constrain the momenta
  of the neutrinos produced in tau decays, as remnants of the colliding protons
  carry away an unknown amount of energy and longitudinal momentum.
}:
\begin{eqnarray*}
\sum p_{x}^{\nu} & = & \METx = -\sum p_{x}^{rec} \\
\sum p_{y}^{\nu} & = & \METy = -\sum p_{y}^{rec}.
\end{eqnarray*}
The sums on the right extend over all particles reconstructed by the particle--flow (PF) algorithm~\cite{PFT-09-001}.

Differences between $\sum p_{x}^{\nu}$ and $\METx$ ($\sum p_{y}^{\nu}$ and $\METy$) 
may arise due to resolution effects and are accounted for in the probability model, assuming a Gaussian resolution.
The logarithm of the \MET likelihood, $\log \cal{L}$, is computed based on the residual between the sum of neutrino momenta
for a given tau decay hypothesis and the value of \MET in the event, reconstructed using the PF algorithm:
\begin{equation}
\log \cal{L}_{MET} = \frac{1}{2}
 \left( \begin{array}{c} \mbox{\METx} - \sum p_{x}^{\nu} \\ \mbox{\METy} - \sum p_{y}^{\nu} \end{array} \right)^{T}
\cdot V^{-1} \cdot
 \left( \begin{array}{c} \mbox{\METx} - \sum p_{x}^{\nu} \\ \mbox{\METy} - \sum p_{y}^{\nu} \end{array} \right).
\end{equation}
The expected resolution of the \MET reconstruction is represented by the covariance matrix $V$ 
and is estimated on an event--by--event basis by the \MET--significance algorithm~\cite{Chatrchyan:2011tn}.
%Typical resolutions on the two components \METx and \METy 
%in the 2011/2012 data--taking period are $\sigma\METx = \sigma\METy \sim 15$~GeV~\cite{DP_12_003,DP_12_013}.

